from Standard.Base import all
import Standard.Base.Errors.Common.Dry_Run_Operation
import Standard.Base.Errors.Common.Missing_Argument
import Standard.Base.Errors.Deprecated.Deprecated
import Standard.Base.Errors.File_Error.File_Error
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.Illegal_State.Illegal_State
import Standard.Base.Runtime.Context
import Standard.Base.Runtime.Managed_Resource.Managed_Resource
import Standard.Base.Runtime.Ref.Ref

from Standard.Table import Table, Match_Columns, Excel_Format, Excel_Range, Data_Formatter, Delimited_Format, Excel_Workbook, Value_Type
from Standard.Table.Errors import Invalid_Column_Names, Duplicate_Output_Column_Names, Invalid_Location, Range_Exceeded, Existing_Data, Column_Count_Mismatch, Column_Name_Mismatch, Empty_Sheet, No_Rows, No_Common_Type
from Standard.Table.Extensions.Excel_Extensions import all
import Standard.Table.Excel.Excel_Workbook.Return_As as Old_Return_As

from Standard.Test import all


import Standard.Examples

import project.Util
from project.Common_Table_Operations.Util import within_table
from project.IO.Read_Many_Spec import with_temp_dir

polyglot java import org.enso.table_test_helpers.RandomHelpers
polyglot java import org.enso.table.excel.ExcelConnectionPool

spec_fmt suite_builder header file read_method sheet_count=5 =
    suite_builder.group header group_builder->
        group_builder.specify "should read a workbook in" <|
            wb = read_method file
            wb.sheet_count . should_equal sheet_count

        group_builder.specify "should read the specified sheet by index and use correct headers" <|
            t = read_method file (..Sheet 1)
            t.columns.map .name . should_equal ['Name', 'Quantity', 'Price']
            t.at 'Name' . to_vector . should_equal ['blouse', 't-shirt', 'trousers', 'shoes', 'skirt', 'dress']
            t.at 'Quantity' . to_vector . should_equal [10, 20, Nothing, 30, Nothing, 5]
            t.at 'Price' . to_vector . should_equal [22.3, 32, 43.2, 54, 31, Nothing]

        group_builder.specify "should read the specified sheet by index and properly format a table" <|
            t = read_method file (..Sheet 2 headers=False)
            t.columns.map .name . should_equal ['A', 'B', 'C', 'D', 'E']
            t.at 'A' . to_vector . should_equal [Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing]
            t.at 'B' . to_vector . should_equal [Nothing, Nothing, 10, Nothing, Nothing, Nothing, Nothing]
            t.at 'C' . to_vector . should_equal [Nothing, 'baz', 20, Nothing, 'bar', Nothing, 30]
            t.at 'D' . to_vector . should_equal [Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing]
            t.at 'E' . to_vector . should_equal [Nothing, Nothing, Nothing, Nothing, Nothing, 'foo', Nothing]

        group_builder.specify "should read the specified sheet by name and properly handle dates" <|
            t = read_method file (..Sheet 'Dates')
            t.columns.map .name . should_equal ['Student Name', 'Enrolment Date']
            t.at 'Enrolment Date' . map .day . to_vector . should_equal [2, 26, 4, 24, 31, 7]

        group_builder.specify "should give an informative error when reading an empty table" <|
            t = read_method file (..Sheet "Empty")
            t.should_fail_with Empty_Sheet

        group_builder.specify "should gracefully handle duplicate column names and formulas" <|
            t = read_method file (..Sheet "Duplicate Columns")
            t.columns.map .name . should_equal ['Item', 'Price', 'Quantity', 'Price 1']
            t.at 'Price 1' . to_vector . should_equal [20, 40, 0, 60, 0, 10]

        group_builder.specify "should allow reading with limited rows and skipping rows from workbook" <|
            wb = read_method file
            t = wb.read 1 headers=..No_Headers
            t.column_names.should_equal ['A', 'B', 'C']

            t_1 = wb.read 1 headers=..No_Headers limit=3
            t_1.column_names . should_equal t.column_names
            t_1.row_count . should_equal 3
            t_1.at 'A' . to_vector . should_equal  ['Name', 'blouse', 't-shirt']
            t_1.at 'B' . to_vector . should_equal  ['Quantity', 10, 20]
            t_1.at 'C' . to_vector . should_equal  ['Price', 22.3, 32]

            t_2 = wb.read 1 headers=..No_Headers skip_rows=3
            t_2.column_names . should_equal t.column_names
            t_2.row_count . should_equal 4
            t_2.at 'A' . to_vector . should_equal ['trousers', 'shoes', 'skirt', 'dress']
            t_2.at 'B' . to_vector . should_equal [Nothing, 30, Nothing, 5]
            t_2.at 'C' . to_vector . should_equal [43.2, 54, 31, Nothing]

            t_3 = wb.read 1 headers=..No_Headers limit=2 skip_rows=3
            t_3.column_names . should_equal t.column_names
            t_3.row_count . should_equal 2
            t_3.at 'A' . to_vector . should_equal ['trousers', 'shoes']
            t_3.at 'B' . to_vector . should_equal [Nothing, 30]
            t_3.at 'C' . to_vector . should_equal [43.2, 54]

        group_builder.specify "should allow reading with cell range specified" <|
            t_1 = read_method file (..Range "Simple!B:C")
            t_1.columns.map .name . should_equal ['Quantity', 'Price']
            t_1.at 'Quantity' . to_vector . should_equal [10, 20, Nothing, 30, Nothing, 5]
            t_1.at 'Price' . to_vector . should_equal [22.3, 32, 43.2, 54, 31, Nothing]

            t_2 = read_method file (..Range "Simple!3:5" headers=False)
            t_2.column_count.should_equal 3
            t_2.at 'A' . to_vector . should_equal ['t-shirt', 'trousers', 'shoes']
            t_2.at 'B' . to_vector . should_equal [20, Nothing, 30]
            t_2.at 'C' . to_vector . should_equal [32, 43.2, 54]

            t_3 = read_method file (..Range "Simple!B4:C5" headers=False)
            t_3.column_count.should_equal 2
            t_3.at 'B' . to_vector . should_equal [Nothing, 30]
            t_3.at 'C' . to_vector . should_equal [43.2, 54]

        group_builder.specify "should let you read all sheets into a single table" <|
            wb = read_method file
            r1 = wb.read_many on_problems=..Report_Error
            r1.should_fail_with Empty_Sheet

            r2 = wb.read_many on_problems=..Report_Warning
            r2.row_count . should_equal 25
            r2.column_names . should_equal ["Sheet Name", "Name", "Quantity", "Price", "A", "B", "C", "D", "E", "Student Name", "Enrolment Date", "Item", "Price 1"]
            # We also ensure how many rows were loaded from each sheet. There should be no entries for the "Empty" sheet.
            r2.at "Sheet Name" . to_vector . should_equal <|
                (Vector.fill 6 "Simple") + (Vector.fill 7 "Strange Dimensions") + (Vector.fill 6 "Dates") + (Vector.fill 6 "Duplicate Columns")
            w1 = Problems.expect_warning No_Rows r2
            w1.to_display_text . should_contain "The sheet Empty failed to load"
            w1.to_display_text . should_contain "There is no data in the sheet."
            w2 = Problems.expect_warning Duplicate_Output_Column_Names r2
            w2.column_names . should_equal ["Price"]

        group_builder.specify "should let you read all sheets into a table of tables" <|
            wb = read_method file
            action = wb.read_many return=..With_New_Column on_problems=_
            tester table =
                table.row_count . should_equal 5
                table.column_names . should_equal ["Sheet Name", "Table"]
            problems = [Empty_Sheet.Error, Duplicate_Output_Column_Names.Error ["Price"]]
            Problems.test_problem_handling action problems tester ignore_warning_cardinality=True

        group_builder.specify "should still support the old options for compatibility" <|
            wb = read_method file
            table1 = wb.read_many return=..Table_Of_Tables
            table1.row_count . should_equal 5
            table1.column_names . should_equal ["Sheet Name", "Table"]
            Problems.expect_warning Deprecated table1

            table2 = wb.read_many return=Old_Return_As.Merged_Table
            table2.row_count . should_equal 25
            Problems.expect_warning Deprecated table2

            table3 = wb.read_many return=..Merged_Table
            table3.row_count . should_equal 25
            Problems.expect_warning Deprecated table3

        group_builder.specify "should let you read some sheets from xlsx" <|
            wb = read_method file
            single_table = wb.read_many ["Simple", "Dates"]
            single_table.row_count . should_equal 12
            single_table.column_names . should_equal ["Sheet Name", "Name", "Quantity", "Price", "Student Name", "Enrolment Date"]
            Problems.assume_no_problems single_table

        group_builder.specify "should let you read some sheets with a bad name from xlsx" <|
            wb = read_method file
            single_table = wb.read_many ["Simple", "Dates", "Not A Sheet"]
            single_table.row_count . should_equal 12
            single_table.column_names . should_equal ["Sheet Name", "Name", "Quantity", "Price", "Student Name", "Enrolment Date"]
            single_table.has_warnings.should_be_true
            warning = Problems.expect_only_warning No_Rows single_table
            warning.to_display_text . should_contain "Unknown sheet or range name or invalid address: 'Not A Sheet'."

type Spec_Write_Data
    Value ~data counter suffix prefix

    table self = self.data.at 0
    clothes self = self.data.at 1
    sub_clothes self = self.data.at 2

    setup suffix =
        table = enso_project.data/'varied_column.csv' . read
        clothes = enso_project.data/'clothes.csv' . read
        sub_clothes = clothes.select_columns [0, 1]
        counter = Ref.new 0
        prefix = "out_" + (Random.integer 1 10000).to_text + "_"
        Spec_Write_Data.Value [table, clothes, sub_clothes] counter suffix prefix

    teardown self =
        enso_project.data/"transient" . list (self.prefix+"*") . each f->
            f.delete . catch Any error-> IO.println "[CLEANUP] Failed to delete "+f.to_text+": "+error.to_display_text

    create_out self suffix=self.suffix =
        i = self.counter.get + 1
        self.counter.put i
        f = enso_project.data / "transient" / (self.prefix + i.to_text + "." + suffix)
        Panic.rethrow f.delete_if_exists
        f

type Complex
    Value re:Float im:Float

type Complex_With_To_String
    Value re:Float im:Float
    to_text self = self.re.to_text + " + " + self.im.to_text + "i"

spec_write suite_builder suffix test_sheet_name =
    suite_builder.group ("Write " + suffix + " Files") group_builder->
        data = Spec_Write_Data.setup suffix

        group_builder.teardown <|
            data.teardown

        group_builder.specify 'should write a table to non-existent file as a new sheet with headers; and return the file object on success' <|
            out = data.create_out
            data.table.write out on_problems=..Report_Error . should_succeed . should_equal out
            written = out.read
            written.sheet_count . should_equal 1
            written.sheet_names . should_equal ['EnsoSheet']
            written.read 'EnsoSheet' . should_equal data.table
            written.close

        group_builder.specify 'should be able to round trip all the data types' <|
            alltypes = enso_project.data / "transient" / ("alltypes."+suffix)
            alltypes.delete_if_exists . should_succeed
            t1 = enso_project.data/'all_data_types.csv' . read
            t1.write alltypes (..Sheet "AllTypes") . should_succeed
            t2 = alltypes.read (..Sheet "AllTypes")
            t2.should_equal t1


        group_builder.specify 'should write a table to non-existent file in append mode as a new sheet with headers' <|
            out = data.create_out
            data.table.write out on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read
            written.sheet_count . should_equal 1
            written.sheet_names . should_equal ['EnsoSheet']
            written.read 'EnsoSheet' . should_equal data.table
            written.close

        group_builder.specify 'should write a table to existing file overriding EnsoSheet' <|
            out = data.create_out
            data.table.write out on_problems=..Report_Error . should_succeed
            data.table.write out on_problems=..Report_Error . should_succeed
            written_workbook = out.read
            written_workbook.sheet_count . should_equal 1
            written_workbook.sheet_names . should_equal ['EnsoSheet']
            written_workbook.read 'EnsoSheet' . should_equal data.table
            written_workbook.close

        group_builder.specify 'should write a table to existing file in overwrite mode as a new sheet with headers' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.table.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Overwrite on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another")
            written.should_equal data.table

        group_builder.specify 'should write a table to existing file in overwrite mode as a new sheet without headers' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.table.write out (..Sheet "NoHeaders") on_existing_file=Existing_File_Behavior.Overwrite on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "NoHeaders")
            written.should_equal (data.table.rename_columns ['A', 'B', 'C', 'D', 'E', 'F'])

        group_builder.specify 'should create new sheets at the start if index is 0' <|
            out = data.create_out
            data.table.write out (..Sheet 0) on_problems=..Report_Error . should_succeed
            data.clothes.write out (..Sheet 0) on_problems=..Report_Error . should_succeed
            read_1 = out.read (..Sheet "Sheet1")
            read_1 . should_equal data.table
            read_2 = out.read (..Sheet "Sheet2")
            read_2 . should_equal data.clothes
            written = out.read
            read_3 = written.sheet_names
            read_3 . should_equal ["Sheet2", "Sheet1"]
            written.close

        group_builder.specify 'should write a table to specific single cell location of an existing sheet' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.table.write out (..Range "Another!G1") on_problems=..Report_Error . should_succeed
            written = out.read (..Range "Another!G1")
            written.should_equal data.table

        group_builder.specify 'should clear out an existing fixed range and replace' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.sub_clothes.write out (..Range "Another!A1:D20") on_problems=..Report_Error . should_succeed
            written = out.read (..Range "Another!A1")
            written.should_equal data.sub_clothes

        group_builder.specify 'should clear out an existing range and replace' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.sub_clothes.write out (..Range "Another!A1") on_problems=..Report_Error . should_succeed
            written = out.read (..Range "Another!A1")
            written.should_equal data.sub_clothes

        group_builder.specify 'should result in Invalid_Location error if trying to write in a bad location' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.sub_clothes.write out (..Range "DoesNotExist!A1") . should_fail_with Invalid_Location
            data.sub_clothes.write out (..Range "DoesNotExist!A1:B2") . should_fail_with Invalid_Location
            data.sub_clothes.write out (..Range "SillyRangeName") . should_fail_with Invalid_Location

        group_builder.specify 'should result in Range_Exceeded error if trying to write in too small a range' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            data.sub_clothes.write out (..Range "Another!A1:B2") . should_fail_with Range_Exceeded

        group_builder.specify 'should result in Existing_Data error if in Error mode and trying to replace' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            r1 = data.sub_clothes.write out (..Sheet 1) on_existing_file=Existing_File_Behavior.Error
            r1.should_fail_with File_Error
            r1.catch.should_be_a File_Error.Already_Exists

            data.sub_clothes.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Error . should_fail_with File_Error
            data.sub_clothes.write out (..Range "Another!A1") on_existing_file=Existing_File_Behavior.Error . should_fail_with File_Error
            data.sub_clothes.write out (..Range "Sheet1!A9") on_existing_file=Existing_File_Behavior.Error . should_fail_with File_Error

            Test.with_clue "the original file should remain unmodified: " <|
                out.last_modified_time.should_equal lmd

        group_builder.specify 'should not allow adding a new sheet if in Error mode, even if sheet is not clashing' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            result = data.sub_clothes.write out (..Sheet "Testing") on_existing_file=Existing_File_Behavior.Error
            result.should_fail_with File_Error
            result.catch.should_be_a File_Error.Already_Exists
            Test.with_clue "the original file should remain unmodified: " <|
                out.last_modified_time.should_equal lmd

        group_builder.specify 'should write a table to non-existent file as a new sheet without headers' <|
            out = data.create_out
            data.table.write out (..Sheet "Sheet1" headers=False) on_problems=..Report_Error . should_succeed
            written = out.read
            written.sheet_count . should_equal 1
            written.sheet_names . should_equal ['Sheet1']
            written.read 'Sheet1' . should_equal (data.table.rename_columns ['A', 'B', 'C', 'D', 'E', 'F'])

            # We need to close the workbook to be able to delete it.
            written.close

        group_builder.specify 'should be able to append to a sheet by name' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['AA', ['d', 'e']], ['BB',[4, 5]], ['CC',[True, False]], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a sheet by position' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['A', ['d', 'e']], ['B',[4, 5]], ['C',[True, False]], ['D', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a sheet by name out of order' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a single cell by name' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['AA', ['d', 'e']], ['BB',[4, 5]], ['CC',[True, False]], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Another!A1") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a single cell by position' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['A', ['d', 'e']], ['B',[4, 5]], ['C',[True, False]], ['D', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Another!A1") on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a single cell by name out of order' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Another!A1") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a range by name' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['AA', ['d', 'e']], ['BB', [4, 5]], ['CC', [True, False]], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a', 'b', 'c', 'd', 'e']], ['BB', [1, 2, 3, 4, 5]], ['CC', [True, False, False, True, False]]]
            extra_another.write out (..Range "Another!A1:D6") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a range by position' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['A', ['d', 'e']], ['B',[4, 5]], ['C',[True, False]], ['D', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Another!A1:D6") on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a range by name not in top left' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['AA', ['d', 'e']], ['BB',[4, 5]], ['CC',[True, False]], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['f', 'g', 'h', 'd', 'e']], ['BB',[1, 2, 3, 4, 5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Random!K9") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Range "Random!K9") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a range by name after deduplication of names' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['AA', ['d', 'e']], ['BB',[4, 5]], ['AA 1',[True, False]], ['BB 1', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['f', 'g', 'h', 'd', 'e']], ['BB',[1, 2, 3, 4, 5]], ['AA 1',[True, False, False, True, False]]]
            extra_another.write out (..Range "Random!S3") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Range "Random!S3") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a range by position not in top left' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['A', ['d', 'e']], ['B',[4, 5]], ['C',[True, False]], ['D', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['f', 'g', 'h', 'd', 'e']], ['BB',[1, 2, 3, 4, 5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Random!K9") on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position on_problems=..Report_Error . should_succeed
            written = out.read (..Range "Random!K9") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should be able to append to a range by name out of order' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']], ['DD', ['2022-01-20', '2022-01-21']]]
            expected = Table.new [['AA', ['a','b','c','d', 'e']], ['BB',[1,2,3,4,5]], ['CC',[True, False, False, True, False]]]
            extra_another.write out (..Range "Another!A1:D6") on_existing_file=Existing_File_Behavior.Append on_problems=..Report_Error . should_succeed
            written = out.read (..Sheet "Another") . select_columns [0, 1, 2]
            written.should_equal expected

        group_builder.specify 'should error gracefully if an unknown extension' <|
            out = data.create_out suffix="notxls"
            data.table.write out format=..Workbook on_problems=..Report_Error . should_fail_with Illegal_Argument
            data.table.write out format=..Sheet on_problems=..Report_Error . should_fail_with Illegal_Argument

        group_builder.specify 'should be able to write to a new dry run file' <|
            out = data.create_out
            temp = Context.Output.with_disabled <|
                result = data.table.write out on_problems=..Report_Error . should_succeed
                Problems.expect_only_warning Dry_Run_Operation result
                result.exists.should_be_true

                result.absolute.normalize.path . should_not_equal out.absolute.normalize.path

                written = result.read
                written.sheet_count . should_equal 1
                written.sheet_names . should_equal ['EnsoSheet']
                written.read 'EnsoSheet' . should_equal data.table
                written.close
                result
            temp.delete_if_exists

        group_builder.specify "should be able to write to a dry-run file, even if the dry-run workbook is open" <|
            out = data.create_out
            out.exists.should_be_false
            temp = Context.Output.with_disabled <|
                result = data.table.write out on_problems=..Report_Error . should_succeed
                Problems.expect_only_warning Dry_Run_Operation result
                result.exists.should_be_true
                result
            temp.absolute.normalize.path . should_not_equal out.absolute.normalize.path
            out.exists.should_be_false

            opened_temp = temp.read
            opened_temp.sheet_names . should_equal ['EnsoSheet']

            temp2 = Context.Output.with_disabled <|
                result = data.table.write out (..Sheet "Another") on_problems=..Report_Error . should_succeed
                Problems.expect_only_warning Dry_Run_Operation result
                result.exists.should_be_true
                result

            # The result should be written to the same dry-run file on second attempt.
            temp2.absolute.normalize.path . should_equal temp.absolute.normalize.path

            ## The write operation replaces the dry run file, basing off of the _original_ out file
               (which was empty in this example), so we still only get one sheet.
               Different example is tested in the test below, if the subsequent file happens to the returned
               dry-run object - then both updates are visible - see below.
            opened_temp.sheet_names . should_equal ['Another']

            opened_temp.close
            temp.delete_if_exists

        group_builder.specify "should be able to write to a dry-run file multiple times if the dry-run file object is threaded through" <|
            out = data.create_out
            temp1 = Context.Output.with_disabled <|
                result = data.table.write out on_problems=..Report_Error . should_succeed
                Problems.expect_only_warning Dry_Run_Operation result
                result.exists.should_be_true
                result
            temp1.absolute.normalize.path . should_not_equal out.absolute.normalize.path

            opened_temp = temp1.read
            opened_temp.sheet_names . should_equal ['EnsoSheet']

            temp2 = Context.Output.with_disabled <|
                result = data.table.write temp1 (..Sheet "Another") on_problems=..Report_Error . should_succeed
                Problems.expect_only_warning Dry_Run_Operation result
                result.exists.should_be_true
                result

            # The result should be written to the same file though.
            temp2.absolute.normalize.path . should_equal temp1.absolute.normalize.path

            # The write operation replaces the dry run file, basing off of the dry-run file itself - so both changes are visible.
            opened_temp.sheet_names . should_equal ['EnsoSheet', 'Another']

            opened_temp.close
            temp1.delete_if_exists

        group_builder.specify "should be able to create a backup, even if it is currently open" <|
            out = data.create_out
            bak = out.parent / (out.name+".bak")

            t1 = Table.new [["X", [1]]]
            t1.write out on_existing_file=Existing_File_Behavior.Backup on_problems=..Report_Error . should_succeed
            bak.exists.should_be_false

            t2 = Table.new [["X", [2]]]
            t2.write out on_existing_file=Existing_File_Behavior.Backup on_problems=..Report_Error . should_succeed
            bak.exists.should_be_true

            opened_out = out.read
            # We need to specify explicit format for the backup, because the extension is changed:
            opened_backup = bak.read (..Workbook xls_format=(suffix=="xls"))

            opened_out.read 'EnsoSheet' . should_equal t2
            opened_backup.read 'EnsoSheet' . should_equal t1

            t3 = Table.new [["X", [3]]]
            t3.write out on_existing_file=Existing_File_Behavior.Backup on_problems=..Report_Error . should_succeed

            opened_out.read 'EnsoSheet' . should_equal t3
            # The backup should actually have been updated
            opened_backup.read 'EnsoSheet' . should_equal t2

            opened_out.close
            opened_backup.close

            bak.delete_if_exists . should_succeed

        group_builder.specify 'should be able to write to an existing empty file' <|
            out = data.create_out
            [].write_bytes out

            out_bak = out.parent / (out.name+".bak")

            data.table.write out on_problems=..Report_Error . should_succeed . should_equal out
            written = out.read
            written.sheet_count . should_equal 1
            written.sheet_names . should_equal ['EnsoSheet']
            written.read 'EnsoSheet' . should_equal data.table

            Test.with_clue "should have created a backup file: " <|
                out_bak.exists.should_be_true
                out_bak.size.should_equal 0

            written.close
            out_bak.delete_if_exists . should_succeed

        group_builder.specify 'should fail to append to a sheet by name if missing columns' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append . should_fail_with Column_Name_Mismatch

        group_builder.specify 'should fail to append to a sheet by name if extra columns' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']], ['DD', ['2022-01-20', '2022-01-21']], ['EE', ['2022-01-20', '2022-01-21']]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append . should_fail_with Column_Name_Mismatch
            out.last_modified_time.should_equal lmd

        group_builder.specify 'should fail to append to a sheet by name if no headers' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']], ['DD', ['2022-01-20', '2022-01-21']], ['EE', ['2022-01-20', '2022-01-21']]]
            extra_another.write out (..Sheet "NoHeaders") on_existing_file=Existing_File_Behavior.Append . should_fail_with Illegal_Argument
            extra_another.write out (..Sheet "Another" headers=False) on_existing_file=Existing_File_Behavior.Append . should_fail_with Illegal_Argument
            out.last_modified_time.should_equal lmd

        group_builder.specify 'should fail to append to a sheet by position if too few columns' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position . should_fail_with Column_Count_Mismatch
            out.last_modified_time.should_equal lmd

        group_builder.specify 'should fail to append to a sheet by position if too many columns' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            extra_another = Table.new [['CC',[True, False]], ['BB',[4, 5]], ['AA', ['d', 'e']], ['DD', ['2022-01-20', '2022-01-21']], ['EE', ['2022-01-20', '2022-01-21']]]
            extra_another.write out (..Sheet "Another") on_existing_file=Existing_File_Behavior.Append match_columns=Match_Columns.By_Position . should_fail_with Column_Count_Mismatch
            out.last_modified_time.should_equal lmd

        group_builder.specify 'should fail to append to a range by name if not large enough' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            extra_another = Table.new [['AA', ['d', 'e']], ['BB',[4, 5]], ['CC',[True, False]], ['DD', ['2022-01-20', '2022-01-21']]]
            extra_another.write out (..Range "Another!A1:D5") on_existing_file=Existing_File_Behavior.Append . should_fail_with Range_Exceeded
            out.last_modified_time.should_equal lmd

        group_builder.specify 'should fail to append to a range by name if it hits another table' <|
            out = data.create_out
            (enso_project.data / test_sheet_name) . copy_to out
            lmd = out.last_modified_time
            extra_another = Table.new [['AA', ['d', 'e']], ['BB',[4, 5]], ['CC',[True, False]], ['DD', ['2022-01-20', '2022-01-21']]]
            extra_another.write out (..Range "Random!B3") on_existing_file=Existing_File_Behavior.Append . should_fail_with Existing_Data
            out.last_modified_time.should_equal lmd

        group_builder.specify "should fail if the target file is read-only" <|
            f = enso_project.data / "transient" / ("permission."+suffix)
            if f.exists then Util.set_writable f True
            f.delete_if_exists

            initial_data = Table.new [["Y", [10, 20, 30]]]
            initial_data.write f . should_succeed
            Util.set_writable f False . should_succeed

            t1 = Table.new [["X", [1, 2, 3]]]
            [Existing_File_Behavior.Backup, Existing_File_Behavior.Overwrite, Existing_File_Behavior.Append].each behavior-> Test.with_clue behavior.to_text+": " <|
                f.exists . should_be_true

                r1 = t1.write f (..Sheet "Another") on_existing_file=behavior
                Test.with_clue "("+r1.catch.to_display_text+") " <|
                    r1.should_fail_with File_Error
                    r1.catch.should_be_a File_Error.Access_Denied

                read_table = Managed_Resource.bracket (f.read) (.close) workbook->
                    workbook.read "EnsoSheet"
                read_table.should_equal initial_data

            Util.set_writable f True
            f.delete

        group_builder.specify "should allow to write to a workbook that is open, and reflect that changes when the sheet is read again" <|
            out = data.create_out
            data.table.write out on_problems=..Report_Error . should_succeed

            workbook = out.read
            workbook.sheet_names.should_equal ["EnsoSheet"]
            workbook.to_text . should_equal "Excel_Workbook ("+out.name+")"

            # We can have the workbook open multiple times in parallel too.
            w2 = out.read

            t1 = workbook.read "EnsoSheet" headers=True
            t1.should_equal data.table

            [Existing_File_Behavior.Backup, Existing_File_Behavior.Overwrite].each behavior-> Test.with_clue behavior.to_text+": " <|
                t2 = Table.new [["X", [behavior.to_text, "B", "C", behavior.to_text+"..."]]]
                t2.write out on_existing_file=behavior . should_succeed

                workbook.sheet_names.should_equal ["EnsoSheet"]

                # If we read the table again, it has the new values in it:
                t3 = workbook.read "EnsoSheet" headers=True
                t3.should_equal t2

                t4 = w2.read "EnsoSheet" headers=True
                t4.should_equal t2

            # And finally test appending:
            (Table.new [["Z", ["a", "b"]]]).write out on_existing_file=Existing_File_Behavior.Overwrite . should_succeed
            (Table.new [["Z", ["c", "d"]]]).write out on_existing_file=Existing_File_Behavior.Append . should_succeed
            w2.read "EnsoSheet" headers=True . should_equal (Table.new [["Z", ["a", "b", "c", "d"]]])

            workbook.close
            w2.close

        group_builder.specify "should fail if the parent directory does not exist" <|
            parent = enso_project.data / "transient" / "nonexistent"
            parent.exists.should_be_false

            f = parent / ("foo."+suffix)
            t1 = Table.new [["X", [1, 2, 3]]]
            r1 = t1.write f (..Sheet "Another")
            Test.with_clue "("+r1.catch.to_display_text+") " <|
                r1.should_fail_with File_Error
                r1.catch.should_be_a File_Error.Not_Found

        group_builder.specify "should allow to write and read-back Unicode characters" <|
            encodings = enso_project.data / "transient" / ("encodings."+suffix)
            encodings.delete_if_exists . should_succeed

            t1 = Table.new [["A", ["A", "B", "😊", "D"]], ["B", [1, 2, 3, 4]]]
            t1.write encodings (..Sheet "Another") . should_succeed
            t2 = encodings.read (..Sheet "Another")
            t2.at "A" . to_vector . should_equal ["A", "B", "😊", "D"]
            encodings.delete

        group_builder.specify "should allow to writing custom types" <|
            custom_types = enso_project.data / "transient" / ("custom_types."+suffix)
            custom_types.delete_if_exists . should_succeed

            t1 = Table.new [["A", [Complex.Value 19 89, Complex.Value -1 -42]], ["B", [1, 2]]]
            t1.write custom_types (..Sheet "Another") . should_succeed
            t2 = custom_types.read (..Sheet "Another")
            t2.at "A" . to_vector . should_equal ["(Complex.Value 19.0 89.0)", "(Complex.Value -1.0 -42.0)"]
            custom_types.delete

        group_builder.specify "should allow to writing custom types that have defined to_string" <|
            custom_types2 = enso_project.data / "transient" / ("custom_types2."+suffix)
            custom_types2.delete_if_exists . should_succeed

            t1 = Table.new [["A", [Complex_With_To_String.Value 19 89, Complex_With_To_String.Value -1 -42]], ["B", [1, 2]]]
            t1.write custom_types2 (..Sheet "Another") . should_succeed
            t2 = custom_types2.read (..Sheet "Another")
            t2.at "A" . to_vector . should_equal ["19.0 + 89.0i", "-1.0 + -42.0i"]
            custom_types2.delete

        group_builder.specify "should be able to overwrite a pre-existing empty file" <|
            empty = enso_project.data / "transient" / ("empty."+suffix)
            [Existing_File_Behavior.Backup, Existing_File_Behavior.Overwrite, Existing_File_Behavior.Append].each behavior-> Test.with_clue behavior.to_text+": " <|
                empty.delete_if_exists . should_succeed
                "".write empty
                empty.exists.should_be_true
                empty.size.should_equal 0

                t1 = Table.new [["A", [behavior.to_text, "B", "C", "D"]], ["B", [1, 2, 3, 4]]]
                t1.write empty on_existing_file=behavior . should_succeed
                empty.exists.should_be_true

                t2 = empty.read (..Sheet "EnsoSheet")
                t2.should_equal t1
                empty.delete


check_range excel_range sheet_name tlbr_vector single_cell=False =
    excel_range.sheet_name . should_equal sheet_name
    excel_range.top_row . should_equal (tlbr_vector.at 0)
    excel_range.left_column . should_equal (tlbr_vector.at 1)
    excel_range.bottom_row . should_equal (tlbr_vector.at 2)
    excel_range.right_column . should_equal (tlbr_vector.at 3)
    excel_range.is_single_cell . should_equal single_cell


add_specs suite_builder =
    suite_builder.group 'Excel Range' group_builder->
        group_builder.specify 'should be able to parse A1 format' <|
            check_range (Excel_Range.from_address "Test!EE4") 'Test' [4, 135, 4, 135] True
            check_range (Excel_Range.from_address "Test!EE4:EE4") 'Test' [4, 135, 4, 135]
            check_range (Excel_Range.from_address "Test!A1:D5") 'Test' [1, 1, 5, 4]
            check_range (Excel_Range.from_address "Test!1234") 'Test' [1234, Nothing, 1234, Nothing]
            check_range (Excel_Range.from_address "Test!1:4") 'Test' [1, Nothing, 4, Nothing]
            check_range (Excel_Range.from_address "Test!CB") 'Test' [Nothing, 80, Nothing, 80]
            check_range (Excel_Range.from_address "Test!DD:XAZ") 'Test' [Nothing, 108, Nothing, 16276]
            check_range (Excel_Range.from_address "'Hello World'!$EE4") 'Hello World' [4, 135, 4, 135] single_cell=True
            check_range (Excel_Range.from_address "Test!A1:$D$5") 'Test' [1, 1, 5, 4]
            check_range (Excel_Range.from_address "Test!1234") 'Test' [1234, Nothing, 1234, Nothing]
            check_range (Excel_Range.from_address "Test!$1:$4") 'Test' [1, Nothing, 4, Nothing]
            check_range (Excel_Range.from_address "Test!$CB") 'Test' [Nothing, 80, Nothing, 80]
            check_range (Excel_Range.from_address "Test!$DD:$XAZ") 'Test' [Nothing, 108, Nothing, 16276]

        group_builder.specify 'should be able to parse RC format' <|
            check_range (Excel_Range.from_address "Test!R1C1") 'Test' [1, 1, 1, 1] True
            check_range (Excel_Range.from_address "Test!R1C1:R5C3") 'Test' [1, 1, 5, 3]

        group_builder.specify 'should fail gracefully for invalid patterns' <|
            Excel_Range.from_address "Test!$$QA1" . should_fail_with Illegal_Argument
            Excel_Range.from_address "Test!BADADDRESS" . should_fail_with Illegal_Argument

        group_builder.specify 'should allow Range creation for a cell' <|
            check_range (Excel_Range.for_cell "Hello World" 123 14) 'Hello World' [14, 123, 14, 123] True
            check_range (Excel_Range.for_cell "Hello World" "DS" 14) 'Hello World' [14, 123, 14, 123] True
            Excel_Range.for_cell "Test" 123 14 . address . should_equal "Test!DS14"
            Excel_Range.for_cell "Hello World" 123 14 . address . should_equal "'Hello World'!DS14"
            Excel_Range.for_cell "Test" 20000 1 . should_fail_with Illegal_Argument
            Excel_Range.for_cell "Test" "ZZZ" 1 . should_fail_with Illegal_Argument
            Excel_Range.for_cell "Test" 0 1 . should_fail_with Illegal_Argument
            Excel_Range.for_cell "Test" 1 10000000 . should_fail_with Illegal_Argument
            Excel_Range.for_cell "Test" 1 0 . should_fail_with Illegal_Argument

        group_builder.specify 'should allow Range creation for a range' <|
            check_range (Excel_Range.for_range "Hello World" 55 120 123 14) 'Hello World' [14, 55, 120, 123]
            check_range (Excel_Range.for_range "Hello World" "BC" 120 "DS" 14) 'Hello World' [14, 55, 120, 123]
            Excel_Range.for_range "Test" 55 120 123 14 . address . should_equal "Test!BC14:DS120"
            Excel_Range.for_range "Hello World" 55 120 123 14 . address . should_equal "'Hello World'!BC14:DS120"
            Excel_Range.for_range "Test" 20000 1 123 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" "ZZZ" 1 123 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 0 1 123 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 5 1 20000 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 5 1 0 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 5 0 123 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 5 10000000 123 14 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 5 1 123 0 . should_fail_with Illegal_Argument
            Excel_Range.for_range "Test" 5 1 123 10000000 . should_fail_with Illegal_Argument

        group_builder.specify 'should allow Range creation for a column' <|
            check_range (Excel_Range.for_columns "Hello World" 123) 'Hello World' [Nothing, 123, Nothing, 123]
            check_range (Excel_Range.for_columns "Hello World" "DS") 'Hello World' [Nothing, 123, Nothing, 123]
            Excel_Range.for_columns "Test" 123 . address . should_equal "Test!DS"
            Excel_Range.for_columns "Hello World" 123 . address . should_equal "'Hello World'!DS"
            Excel_Range.for_columns "Test" 20000 . should_fail_with Illegal_Argument
            Excel_Range.for_columns "Test" "ZZZ" . should_fail_with Illegal_Argument
            Excel_Range.for_columns "Test" 0 . should_fail_with Illegal_Argument

        group_builder.specify 'should allow Range creation for columns' <|
            check_range (Excel_Range.for_columns "Hello World" "BC" 123) 'Hello World' [Nothing, 55, Nothing, 123]
            check_range (Excel_Range.for_columns "Hello World" 55 "DS") 'Hello World' [Nothing, 55, Nothing, 123]
            Excel_Range.for_columns "Test" 55 123 . address . should_equal "Test!BC:DS"
            Excel_Range.for_columns "Hello World" "BC" "DS" . address . should_equal "'Hello World'!BC:DS"
            Excel_Range.for_columns "Test" 55 20000 . should_fail_with Illegal_Argument
            Excel_Range.for_columns "Test" 55 "ZZZ" . should_fail_with Illegal_Argument
            Excel_Range.for_columns "Test" 55 0 . should_fail_with Illegal_Argument

        group_builder.specify 'should allow Range creation for a row' <|
            check_range (Excel_Range.for_rows "Hello World" 123) 'Hello World' [123, Nothing, 123, Nothing]
            Excel_Range.for_rows "Test" 123 . address . should_equal "Test!123"
            Excel_Range.for_rows "Hello World" 123 . address . should_equal "'Hello World'!123"
            Excel_Range.for_rows "Test" 20000000 . should_fail_with Illegal_Argument
            Excel_Range.for_rows "Test" 0 . should_fail_with Illegal_Argument

        group_builder.specify 'should allow Range creation for rows' <|
            check_range (Excel_Range.for_rows "Hello World" 55 123) 'Hello World' [55, Nothing, 123, Nothing]
            Excel_Range.for_rows "Test" 55 123 . address . should_equal "Test!55:123"
            Excel_Range.for_rows "Hello World" 55 123 . address . should_equal "'Hello World'!55:123"
            Excel_Range.for_rows "Test" 55 20000000 . should_fail_with Illegal_Argument
            Excel_Range.for_rows "Test" 55 0 . should_fail_with Illegal_Argument

    xlsx_sheet = enso_project.data / "TestSheet.xlsx"
    xlsx_path = xlsx_sheet.path

    xls_sheet = enso_project.data / "TestSheetOld.xls"
    xls_path = xls_sheet.path

    sheet_names = ["Sheet1", "Another", "NoHeaders", "Random"]
    range_names = ["myData"]

    col_a = ["Test", "Here", "Is", "Data"]
    col_b = [1, 2, 3, 4]
    col_c = [Date.new 2022 06 12, Date.new 2022 10 20, Date.new 2022 07 30, Date.new 2022 10 15]
    col_d = [Time_Of_Day.new 12 34 56, Time_Of_Day.new 1 23 45, Time_Of_Day.new 2 46, Time_Of_Day.new 9]
    col_e = [Date_Time.new 2022 06 12 12 34 56, Date_Time.new 2022 10 20 1 23 45, Date_Time.new 2022 07 30 2 46, Date_Time.new 2022 10 15 9]

    check_column col expected =
        start = col.length - expected.length
        0.up_to start . map i->(col.at i . should_equal Nothing)
        start.up_to col.length . map i->(col.at i . should_equal (expected.at (i - start)))

    check_table table count=5 =
        table.column_count . should_equal count
        if count > 0 then check_column (table.at "A") col_a
        if count > 1 then check_column (table.at "B") col_b
        if count > 2 then check_column (table.at "C") col_c
        if count > 3 then check_column (table.at "D") col_d
        if count > 4 then check_column (table.at "E") col_e

    check_workbook workbook sheets=sheet_names.length ranges=range_names.length =
        workbook.is_a Excel_Workbook . should_be_true
        workbook.sheet_count . should_equal sheets
        workbook.named_ranges_count . should_equal ranges

    suite_builder.group "Read XLSX / XLS Files" group_builder->
        group_builder.specify "should let you read the workbook with Auto_Detect" <|
            check_workbook <| xlsx_sheet.read
            check_workbook <| Data.read xlsx_sheet
            check_workbook <| Data.read xlsx_path

            check_workbook <| xls_sheet.read
            check_workbook <| Data.read xls_sheet
            check_workbook <| Data.read xls_path

        group_builder.specify "should let you read the workbook with Excel" <|
            check_workbook <| xlsx_sheet.read ..Workbook
            check_workbook <| Data.read xlsx_sheet ..Workbook
            check_workbook <| Data.read xlsx_path ..Workbook

            check_workbook <| xls_sheet.read ..Workbook
            check_workbook <| Data.read xls_sheet ..Workbook
            check_workbook <| Data.read xls_path ..Workbook

        group_builder.specify "workbook should look like a database connection" <|
            workbook = xlsx_sheet.read

            workbook.database . should_equal xlsx_sheet.normalize.path
            workbook.schema . should_equal Nothing

            workbook.table_types . should_equal ['Worksheet', 'Named Range']

            workbook.tables.row_count . should_equal (sheet_names.length + range_names.length)
            workbook.tables.at "Name" . to_vector . should_equal_ignoring_order (sheet_names + range_names)

            workbook.tables types=["Worksheet"] . row_count . should_equal sheet_names.length
            workbook.tables types=["Named Range"] . row_count . should_equal range_names.length
            workbook.tables types=["XXX"] . row_count . should_equal 0

            workbook.tables "%not%" . row_count . should_equal 1
            workbook.tables "%not%" . at 'Name' . to_vector . should_equal ["Another"]

        group_builder.specify "should let you read the sheet names" <|
            xlsx_sheet.read . sheet_names . should_equal sheet_names
            xls_sheet.read . sheet_names . should_equal sheet_names

        group_builder.specify "should let you read the range names" <|
            xlsx_sheet.read . named_ranges . should_equal range_names
            xls_sheet.read . named_ranges . should_equal range_names

        group_builder.specify "should let you read by sheet index" <|
            table = xlsx_sheet.read (..Sheet 1)
            check_table table

            table_2 = xlsx_sheet.read (..Sheet 1 skip_rows=(table.row_count - col_a.length))
            table_2.row_count . should_equal col_a.length
            check_table table_2

        group_builder.specify "should let you read by sheet name" <|
            table = xlsx_sheet.read (..Sheet "Sheet1")
            check_table table

            table_2 = xlsx_sheet.read (..Sheet "Sheet1" skip_rows=(table.row_count - col_a.length))
            table_2.row_count . should_equal col_a.length
            check_table table_2

            table_3 = xlsx_sheet.read . read "Sheet1"
            check_table table_3

            table_4 = xlsx_sheet.read . sheet "Sheet1"
            check_table table_4

        group_builder.specify "should error if you read by an invalid sheet name" <|
            xlsx_sheet.read (..Sheet "NoSuchSheet") . should_fail_with Invalid_Location
            xlsx_sheet.read . read "NoSuchSheet" . should_fail_with Invalid_Location

        group_builder.specify "should let you read XLS by sheet index" <|
            table = xls_sheet.read (..Sheet 1)
            check_table table

            table_2 = xls_sheet.read (..Sheet 1 skip_rows=(table.row_count - col_a.length))
            table_2.row_count . should_equal col_a.length
            check_table table_2

            table_4 = xlsx_sheet.read . sheet 1
            check_table table_4

        group_builder.specify "should let you read XLS by sheet name" <|
            table = xls_sheet.read (..Sheet "Sheet1")
            check_table table

            table_2 = xls_sheet.read . read "Sheet1"
            check_table table_2

        group_builder.specify "should let you read by range" <|
            table = xlsx_sheet.read (..Range "Sheet1!A:C")
            check_table table 3

            table_2 = xlsx_sheet.read (..Range "Sheet1!A:C" skip_rows=(table.row_count - col_a.length))
            table_2.row_count . should_equal col_a.length
            check_table table_2 3

            check_table <| xlsx_sheet.read (..Range "Sheet1!10:13")
            check_table count=3 <| xlsx_sheet.read (..Range "Sheet1!A10:C13")

            check_table <| xlsx_sheet.read . read "Sheet1!10:13"
            check_table count=3 <| xlsx_sheet.read . read "Sheet1!A10:C13"

        group_builder.specify "should let you read by range name" <|
            table = xlsx_sheet.read (..Range "myData")
            table.row_count . should_equal col_a.length
            check_table table 3

            table_2 = xlsx_sheet.read . read "myData"
            table_2.row_count . should_equal col_a.length
            check_table table_2 3

        group_builder.specify "should let you restrict number of rows read and skip rows" <|
            table = xlsx_sheet.read (..Sheet "Sheet1")
            check_table table

            table_2 = xlsx_sheet.read (..Sheet "Sheet1" skip_rows=(table.row_count - col_a.length))
            table_2.row_count . should_equal col_a.length
            check_table table_2

            table_3 = xlsx_sheet.read (..Sheet "Sheet1" skip_rows=(table.row_count - col_a.length) row_limit=2)
            table_3.row_count . should_equal 2

            table_4 = xlsx_sheet.read (..Sheet "Sheet1" row_limit=6)
            table_4.row_count . should_equal 6

        group_builder.specify "should let you `read_many` Excel sheets and other tabular files into a Table" <|
            with_temp_dir base_dir->
                (Table.new [["A", [1, 2]], ["B", [3, 4]]]).write (base_dir / "1.tsv") . should_succeed
                (Table.new [["A", [10, 20]], ["B", [30, 40]]]).write (base_dir / "2.xlsx") . should_succeed

                f3 = base_dir / "3.xlsx"
                (Table.new [["A", [100]], ["B", [200]], ["C", [300]]]).write f3 format=(..Sheet "nr 1") on_existing_file=..Overwrite . should_succeed
                (Table.new [["A", [400, 500, 600]]]).write f3 format=(..Sheet "nr 2") on_existing_file=..Append . should_succeed

                files = Data.list base_dir . sort on=(.name)

                r1 = Data.read_many files return=..With_New_Column
                r1.should_be_a Table
                Problems.assume_no_problems r1
                within_table r1 <|
                    r1.column_names . should_equal ["Path", "Value"]
                    r1.row_count . should_equal 3
                    r1.at "Value" . at 0 . should_be_a Table
                    r1.at "Value" . at 1 . should_be_a Excel_Workbook
                    r1.at "Value" . at 2 . should_be_a Excel_Workbook

                r2 = Data.read_many files return=..As_Merged_Table
                r2.should_be_a Table
                Problems.assume_no_problems r2
                within_table r2 <|
                    r2.column_names . should_equal ["Path", "Sheet Name", "A", "B", "C"]

                    # We transform the Path to just file name for easier testing
                    rows = (r2.set (r2.at "Path" . map .name) "Path").rows.map .to_vector
                    rows.at 0 . should_equal ["1.tsv",      Nothing,   1,       3, Nothing]
                    rows.at 1 . should_equal ["1.tsv",      Nothing,   2,       4, Nothing]
                    rows.at 2 . should_equal ["2.xlsx", "EnsoSheet",  10,      30, Nothing]
                    rows.at 3 . should_equal ["2.xlsx", "EnsoSheet",  20,      40, Nothing]
                    rows.at 4 . should_equal ["3.xlsx",      "nr 1", 100,     200,     300]
                    rows.at 5 . should_equal ["3.xlsx",      "nr 2", 400, Nothing, Nothing]
                    rows.at 6 . should_equal ["3.xlsx",      "nr 2", 500, Nothing, Nothing]
                    rows.at 7 . should_equal ["3.xlsx",      "nr 2", 600, Nothing, Nothing]

                # Test loading only Excel files and alternate matching mode to weed out edge cases
                r3 = Data.read_many (Data.list base_dir name_filter="*.xlsx" . sort on=(.name)) return=..As_Merged_Table
                r3.should_be_a Table
                Problems.assume_no_problems r3
                within_table r3 <|
                    r3.column_names . should_equal ["Path", "Sheet Name", "A", "B", "C"]
                    r3.at "Sheet Name" . to_vector . should_equal ["EnsoSheet", "EnsoSheet", "nr 1", "nr 2", "nr 2", "nr 2"]
                    r3.at "A" . to_vector . should_equal [10, 20, 100, 400, 500, 600]

        group_builder.specify "during `read_many`, should not mix metadata columns with data columns with same name or when matching by position" <|
            with_temp_dir base_dir->
                (Table.new [["Z", [1, 2]], ["Sheet Name", ['data column', 'data column']]]).write (base_dir / "1.tsv") . should_succeed
                (Table.new [["Z", [10]], ["X", [20]]]).write (base_dir / "2.xlsx") . should_succeed

                f3 = base_dir / "3.xlsx"
                (Table.new [["X", [100]], ["Y", [200]], ["Z", [300]]]).write f3 format=(..Sheet "nr 1") on_existing_file=..Overwrite . should_succeed
                (Table.new [["Sheet Name", [400, 500, 600]]]).write f3 format=(..Sheet "nr 2") on_existing_file=..Append . should_succeed

                files = Data.list base_dir . sort on=(.name)
                input = Table.new [["Path", files], ["Sheet Name", ["input 1", "input 2", "input 3"]]]
                r1 = Data.read_many input
                r1.should_be_a Table
                within_table r1 <|
                    # We transform the Path to just file name for easier testing
                    rows = (r1.set (r1.at "Path" . map .name) "Path").rows.map .to_vector

                    # Each Sheet Name column comes out as separate: 1 - input, 2 - metadata, 3 - data
                    # The order of columns is as they appear in the input, and they are matched by name
                    r1.column_names . should_equal [  "Path", "Sheet Name", "Sheet Name 1",     "Z", "Sheet Name 2",     "X",     "Y"]
                    rows.at 0 . should_equal       [ "1.tsv",    "input 1",        Nothing,       1,  "data column", Nothing, Nothing]
                    rows.at 1 . should_equal       [ "1.tsv",    "input 1",        Nothing,       2,  "data column", Nothing, Nothing]
                    rows.at 2 . should_equal       ["2.xlsx",    "input 2",    "EnsoSheet",      10,        Nothing,      20, Nothing]
                    rows.at 3 . should_equal       ["3.xlsx",    "input 3",         "nr 1",     300,        Nothing,     100,     200]
                    rows.at 4 . should_equal       ["3.xlsx",    "input 3",         "nr 2", Nothing,          "400", Nothing, Nothing]
                    rows.at 5 . should_equal       ["3.xlsx",    "input 3",         "nr 2", Nothing,          "500", Nothing, Nothing]
                    rows.at 6 . should_equal       ["3.xlsx",    "input 3",         "nr 2", Nothing,          "600", Nothing, Nothing]

                    Problems.expect_warning Duplicate_Output_Column_Names r1
                    Problems.expect_warning No_Common_Type r1

                r2 = Data.read_many input return=(..As_Merged_Table match=..By_Position)
                r2.should_be_a Table
                within_table r2 <|
                    rows = (r2.set (r2.at "Path" . map .name) "Path").rows.map .to_vector

                    # Two Sheet Name column comes out as separate: 1 - input, 2 - metadata, the third one (data) gets renamed due to positional matching
                    # The column names come from the first table that had all the columns - in this case, first sheet of 3.xlsx
                    r2.column_names . should_equal [  "Path", "Sheet Name", "Sheet Name 1", "X",           "Y",     "Z"]
                    rows.at 0 . should_equal       [ "1.tsv",    "input 1",        Nothing,   1, "data column", Nothing]
                    rows.at 1 . should_equal       [ "1.tsv",    "input 1",        Nothing,   2, "data column", Nothing]
                    rows.at 2 . should_equal       ["2.xlsx",    "input 2",    "EnsoSheet",  10,          "20", Nothing]
                    rows.at 3 . should_equal       ["3.xlsx",    "input 3",         "nr 1", 100,         "200",     300]
                    rows.at 4 . should_equal       ["3.xlsx",    "input 3",         "nr 2", 400,       Nothing, Nothing]
                    rows.at 5 . should_equal       ["3.xlsx",    "input 3",         "nr 2", 500,       Nothing, Nothing]
                    rows.at 6 . should_equal       ["3.xlsx",    "input 3",         "nr 2", 600,       Nothing, Nothing]

                    Problems.expect_warning Duplicate_Output_Column_Names r2
                    Problems.expect_warning No_Common_Type r2

                r3 = Data.read_many input return=(..As_Merged_Table columns_to_keep=..In_All match=..By_Position)
                r3.should_be_a Table
                within_table r3 <|
                    rows = (r3.set (r3.at "Path" . map .name) "Path").rows.map .to_vector

                    # Same as with `r2`, but now we keep only columns that are present in all tables, then the column names come from the first table (so we get column Z).
                    # But the `Sheet Name` metadata column is still kept, as its matching is independent of data.
                    r3.column_names . should_equal [  "Path", "Sheet Name", "Sheet Name 1", "Z"]
                    rows.at 0 . should_equal       [ "1.tsv",    "input 1",        Nothing,   1]
                    rows.at 1 . should_equal       [ "1.tsv",    "input 1",        Nothing,   2]
                    rows.at 2 . should_equal       ["2.xlsx",    "input 2",    "EnsoSheet",  10]
                    rows.at 3 . should_equal       ["3.xlsx",    "input 3",         "nr 1", 100]
                    rows.at 4 . should_equal       ["3.xlsx",    "input 3",         "nr 2", 400]
                    rows.at 5 . should_equal       ["3.xlsx",    "input 3",         "nr 2", 500]
                    rows.at 6 . should_equal       ["3.xlsx",    "input 3",         "nr 2", 600]

                    Problems.expect_warning Duplicate_Output_Column_Names r3
                    Problems.expect_warning Column_Count_Mismatch r3

        group_builder.specify "during `read_many`, should correctly handle empty sheets" <|
            with_temp_dir base_dir->
                tsv_file = base_dir / "1.tsv"
                (Table.new [["A", [1, 2]], ["B", [3, 4]]]).write tsv_file . should_succeed
                xls_file = Examples.xls

                r = Data.read_many [tsv_file, xls_file] return=..As_Merged_Table
                r.should_be_a Table
                r.row_count . should_equal 2+25
                r.column_names . should_equal ["Path", "Sheet Name", "A", "B", "Name", "Quantity", "Price", "C", "D", "E", "Student Name", "Enrolment Date", "Item", "Price 1"]
                # First two rows come from TSV, the rest from Excel sheets
                r.at "Path" . to_vector . map .name . should_equal <|
                    (Vector.fill 2 tsv_file.name) + (Vector.fill 25 xls_file.name)
                r.at "Sheet Name" . to_vector . should_equal <|
                    (Vector.fill 2 Nothing) + (Vector.fill 6 "Simple") + (Vector.fill 7 "Strange Dimensions") + (Vector.fill 6 "Dates") + (Vector.fill 6 "Duplicate Columns")

                w = Problems.expect_warning No_Rows r
                w.to_display_text . should_contain "Empty"

                empty_xls_file = enso_project.data / "empty-sheets.xlsx"
                r2 = Data.read_many [tsv_file, empty_xls_file] return=..As_Merged_Table
                r2.should_be_a Table
                r2.row_count . should_equal 2
                # No sheet name columns because after all no data from Excel made it to the result
                r2.column_names . should_equal ["Path", "A", "B"]
                Problems.expect_warning No_Rows r2
                Problems.get_attached_warnings r2
                    . map .to_display_text
                    . find (..Contains "failed to load any sheets")
                    . should_succeed

                # But when not expanding rows, the workbook with all-empty sheets is normally loaded into a cell
                r3 = Data.read_many [tsv_file, empty_xls_file] return=..With_New_Column
                r3.should_be_a Table
                r3.at "Path" . to_vector . map .name . should_equal [tsv_file.name, empty_xls_file.name]
                r3.at "Value" . at 0 . should_be_a Table
                r3.at "Value" . at 1 . should_be_a Excel_Workbook

        group_builder.specify "should clear cache on simulated reload" pending="https://github.com/enso-org/enso/issues/12166" <|
            ExcelConnectionPool.INSTANCE.simulateReloadTestOnly
            check_workbook <| xlsx_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 1
            check_workbook <| xlsx_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 1
            check_workbook <| xls_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 2
            check_workbook <| xls_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 2
            ExcelConnectionPool.INSTANCE.simulateReloadTestOnly
            check_workbook <| xlsx_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 1
            check_workbook <| xlsx_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 1
            check_workbook <| xls_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 2
            check_workbook <| xls_sheet.read
            ExcelConnectionPool.INSTANCE.getConnectionRecordCount . should_equal 2

    suite_builder.group "Problems" group_builder->
        group_builder.specify "should report a user-friendly error message when format is missing a required argument" <|
            r = xlsx_sheet.read (..Range)
            r.should_fail_with Missing_Argument
            r.catch.to_display_text . should_contain "Provide a value for the argument `address`."

        group_builder.specify "should handle non-existing file gracefully" <|
            bad_file = enso_project.data / "DoesNotExists.xlsx"
            result = bad_file.read (..Range "Sheet1!A:C")
            result.should_fail_with File_Error
            result.catch.should_be_a File_Error.Not_Found

        group_builder.specify "should handle wrong xls_format gracefully" <|
            xlsx_sheet_copy = enso_project.data / "transient" / "TestSheetCopy.xlsx"
            xlsx_sheet_copy.delete_if_exists . should_succeed
            xlsx_sheet.copy_to xlsx_sheet_copy

            # At first, it fails with File_Error
            r1 = xlsx_sheet.read (..Range "Sheet1!A:C" xls_format=True)
            r1.should_fail_with File_Error
            r1.catch.should_be_a File_Error.Corrupted_Format

            # If we now open it correctly
            r1_2 = xlsx_sheet.read
            r1_2.should_succeed

            # And then wrong again
            r1_3 = xlsx_sheet.read (..Range "Sheet1!A:C" xls_format=True)
            # It should still fail the same:
            r1_3.should_fail_with File_Error
            r1_3.catch.should_be_a File_Error.Corrupted_Format

            r2 = xls_sheet.read (..Range "Sheet1!A:C" xls_format=False)
            r2.should_fail_with File_Error
            r2.catch.should_be_a File_Error.Corrupted_Format
            xlsx_sheet_copy.delete

        group_builder.specify "should handle malformed XLS files gracefully" <|
            bad_file = enso_project.data / "transient" / "malformed.xls"
            "not really an XLS file contents...".write bad_file on_existing_file=Existing_File_Behavior.Overwrite

            r1 = bad_file.read
            r1.should_fail_with File_Error
            r1.catch.should_be_a File_Error.Corrupted_Format
            r1.catch.to_display_text.should_contain "is corrupted"

            r1a = bad_file.read ..Workbook
            r1a.should_fail_with File_Error
            r1a.catch.should_be_a File_Error.Corrupted_Format

            r2 = bad_file.read (..Range "Sheet1!A:C")
            r2.should_fail_with File_Error
            r2.catch.should_be_a File_Error.Corrupted_Format
            r2.catch.to_display_text.should_contain "is corrupted"

            bad_file.delete

        group_builder.specify "will fail if an operation is performed on a closed workbook" <|
            workbook = xlsx_sheet.read
            workbook.sheet_count . should_equal 4

            workbook.close . should_equal Nothing

            workbook.sheet_count . should_fail_with Illegal_State
            workbook.close . should_equal Nothing
            workbook.read "Sheet1" . should_fail_with Illegal_State

        group_builder.specify "should be able to read a XLSX with inline strings" <|
            workbook = (enso_project.data / "Sales_Sample_Data.xlsx") . read
            workbook.sheet_count . should_equal 29
            workbook.sheet_names . should_equal ['202201', '202202', '202203', '202204', '202205', '202206', '202207', '202208', '202209', '202210', '202211', '202212', '202301', '202302', '202303', '202304', '202305', '202306', '202307', '202308', '202309', '202310', '202311', '202312', '202401', '202402', '202403', '202404', '202405']

            column_names = ['TERRITORY', 'DEALSIZE', 'PRODUCTLINE', 'OrderCount', 'SALES']

            first_sheet = workbook.read '202201'
            first_sheet.column_names . should_equal column_names
            first_sheet.at 'TERRITORY' . to_vector . should_equal ['EMEA', 'NA', 'EMEA', 'EMEA', 'EMEA', 'EMEA', 'NA', 'EMEA', 'EMEA', 'EMEA']
            first_sheet.at 'DEALSIZE' . to_vector . should_equal ['Medium', 'Medium', 'Small', 'Small', 'Small', 'Medium', 'Small', 'Medium', 'Small', 'Medium']
            first_sheet.at 'PRODUCTLINE' . to_vector . should_equal ['Classic Cars', 'Vintage Cars', 'Classic Cars', 'Vintage Cars', 'Trucks and Buses', 'Trains', 'Vintage Cars', 'Vintage Cars', 'Trains', 'Trucks and Buses']
            first_sheet.at 'OrderCount' . to_vector . should_equal [7, 3, 3, 7, 2, 1, 3, 3, 1, 9]
            first_sheet.at 'SALES' . to_vector . should_equal [34585.61, 13349.31, 6606.17, 15482.34, 2856.68, 3227.63, 5647.99, 12347.2, 1705.92, 33944.75]

            last_sheet = workbook.read '202405'
            last_sheet.column_names . should_equal column_names
            last_sheet.at 'TERRITORY' . to_vector . should_equal ['NA', 'EMEA', 'EMEA', 'NA', 'EMEA', 'EMEA', 'NA', 'EMEA', 'EMEA', 'EMEA', 'NA', 'NA', 'EMEA', 'EMEA', 'EMEA', 'NA', 'EMEA', 'NA']
            last_sheet.at 'DEALSIZE' . to_vector . should_equal ['Large', 'Medium', 'Small', 'Medium', 'Medium', 'Small', 'Small', 'Medium', 'Medium', 'Small', 'Medium', 'Small', 'Small', 'Small', 'Large', 'Medium', 'Large', 'Small']
            last_sheet.at 'PRODUCTLINE' . to_vector . should_equal ['Classic Cars', 'Planes', 'Trucks and Buses', 'Classic Cars', 'Trucks and Buses', 'Vintage Cars', 'Vintage Cars', 'Classic Cars', 'Motorcycles', 'Classic Cars', 'Trucks and Buses', 'Trains', 'Planes', 'Motorcycles', 'Classic Cars', 'Trains', 'Trucks and Buses', 'Trucks and Buses']
            last_sheet.at 'OrderCount' . to_vector . should_equal [2, 4, 2, 5, 3, 2, 1, 10, 1, 6, 3, 1, 6, 1, 3, 1, 1, 2]
            last_sheet.at 'SALES' . to_vector . should_equal [16914.55, 17742.36, 3838.83, 22429.29, 14910.28, 3513.13, 2095.45, 46915.8, 4764.6, 8776.53, 14680.72, 1193.04, 12686.65, 2803.2, 28823.4, 3256.35, 8498.0, 4772.04]

        group_builder.specify "should be able to read a mixed Date and DateTime column" <|
            table = (enso_project.data / "MixedExcel.xlsx") . read ..Sheet
            table.row_count . should_equal 5
            table.column_names . should_equal ["Number","Date","DateTimes","Time","MixDates","InvMixDates","Mixed"]
            table.columns.map .value_type . should_equal [Value_Type.Integer, Value_Type.Date, Value_Type.Date_Time, Value_Type.Time, Value_Type.Date_Time, Value_Type.Date_Time, Value_Type.Mixed]
            table.at "Number" . to_vector . should_equal [15,24,43,1,85]
            table.at "Date" . to_vector . should_equal [(Date.new 1997 7 25), (Date.new 1993 5 3), (Date.new 2010 8 1), (Date.new 1988 7 12), (Date.new 2009 10 22)]
            table.at "DateTimes" . to_vector . should_equal [(Date_Time.new 1997 7 25 22 23 28 millisecond=34), (Date_Time.new 1993 5 3 10 58 45 millisecond=980), (Date_Time.new 2010 8 1 17 9 29 millisecond=923), (Date_Time.new 1988 7 12 12 39 20 millisecond=185), (Date_Time.new 2009 10 22 12 33 7 millisecond=157)]
            table.at "Time" . to_vector . should_equal [(Time_Of_Day.new 16 43 42 millisecond=486), (Time_Of_Day.new 1 39 30 millisecond=506), (Time_Of_Day.new 7 44 4 millisecond=567), (Time_Of_Day.new 18 39 24 millisecond=572), (Time_Of_Day.new 10 6 32 millisecond=917)]
            table.at "MixDates" . to_vector . should_equal [(Date_Time.new 1997 7 25 22 23 28 millisecond=34), (Date_Time.new 1993 5 3), (Date_Time.new 2010 8 1), (Date_Time.new 1988 7 12), (Date_Time.new 2009 10 22 12 33 7 millisecond=157)]
            table.at "InvMixDates" . to_vector . should_equal [(Date_Time.new 1997 7 25), (Date_Time.new 1993 5 3 10 58 45 millisecond=980), (Date_Time.new 2010 8 1 17 9 29 millisecond=923), (Date_Time.new 1988 7 12 12 39 20 millisecond=185), (Date_Time.new 2009 10 22)]
            table.at "Mixed" . to_vector . should_equal [(Date.new 1997 7 25), (Date_Time.new 1993 5 3 10 58 45 millisecond=980), (Date_Time.new 2010 8 1 17 9 29 millisecond=923), (Time_Of_Day.new 18 39 24 millisecond=572), 85]

        group_builder.specify "should be able to read dates before 1900-01-01 (treating 1899-12-31 as -1)" <|
            table = (enso_project.data / "OlderDates.xlsx") . read ..Sheet
            table.row_count . should_equal 15
            table.column_names . should_equal ["Num","Date","Date13","NumVal"]
            table.at "Date" . to_vector . should_equal [(Date.new 1899 12 28),(Date.new 1899 12 29),(Date.new 1899 12 30),(Date.new 1899 12 31),(Date.new 1900 1 1),(Date.new 1900 1 2),(Date.new 1900 1 3),(Date.new 1900 1 4),(Date.new 1900 1 5),(Date.new 1900 2 28),Nothing,(Date.new 1900 3 1),(Date.new 1900 3 2),(Date.new 1900 3 3),(Date.new 1900 3 4)]
            table.at "Date13" . to_vector . should_equal [(Date_Time.new 1899 12 28 hour=13),(Date_Time.new 1899 12 29 hour=13),(Date_Time.new 1899 12 30 hour=13),(Date_Time.new 1899 12 31 hour=13),(Date_Time.new 1900 1 1 hour=13),(Date_Time.new 1900 1 2 hour=13),(Date_Time.new 1900 1 3 hour=13),(Date_Time.new 1900 1 4 hour=13),(Date_Time.new 1900 1 5 hour=13),(Date_Time.new 1900 2 28 hour=13),Nothing,(Date_Time.new 1900 3 1 hour=13),(Date_Time.new 1900 3 2 hour=13),(Date_Time.new 1900 3 3 hour=13),(Date_Time.new 1900 3 4 hour=13)]

        group_builder.specify "should be able to write and then read dates before 1900-01-01 (treating 1899-12-31 as -1)" <|
            numbers = [-100,-1,1,2,50,61,100]
            dates = numbers.map n-> (Date.new 1899 12 31).date_add n ..Day
            date_times = dates.map d-> d.to_date_time (Time_Of_Day.new 12 34 56)
            table = Table.new [["Num", numbers], ["Date", dates], ["DateTimes", date_times]]
            file = enso_project.data / "transient" / "TestOlderDates.xlsx"
            file.delete_if_exists . should_succeed
            table.write file . should_succeed
            read_table = file.read ..Sheet
            read_table.should_equal table

        group_builder.specify "should be able to read dates In Excel 1904 format" <|
            table = (enso_project.data / "OlderDates1904.xlsx") . read ..Sheet
            table.row_count . should_equal 15
            table.column_names . should_equal ["Num","Date","Date13","NumVal", "Times"]
            table.at "Date" . to_vector . should_equal [Date.new 1903 12 28, Date.new 1903 12 29, Date.new 1903 12 30, Date.new 1903 12 31, Date.new 1904 1 1, Date.new 1904 1 2, Date.new 1904 1 3, Date.new 1904 1 4, Date.new 1904 1 5, Date.new 1904 2 29, Date.new 1904 3 1, Date.new 1904 3 2, Date.new 1904 3 3, Date.new 1904 3 4, Date.new 1904 3 5]
            table.at "Date13" . to_vector . should_equal [Date_Time.new 1903 12 28 13, Date_Time.new 1903 12 29 13, Date_Time.new 1903 12 30 13, Date_Time.new 1903 12 31 13, Date_Time.new 1904 1 1 13, Date_Time.new 1904 1 2 13, Date_Time.new 1904 1 3 13, Date_Time.new 1904 1 4 13, Date_Time.new 1904 1 5 13, Date_Time.new 1904 2 29 13, Date_Time.new 1904 3 1 13, Date_Time.new 1904 3 2 13, Date_Time.new 1904 3 3 13, Date_Time.new 1904 3 4 13, Date_Time.new 1904 3 5 13]
            table.at "Times" . to_vector . should_equal [Time_Of_Day.new 14 55 52, Time_Of_Day.new 10 30 2, Time_Of_Day.new 23 6 58, Time_Of_Day.new 15 39, Time_Of_Day.new 1 37 21, Time_Of_Day.new 17 16 34, Time_Of_Day.new 10 21 53, Time_Of_Day.new 2 29 9, Time_Of_Day.new 10 20 55, Time_Of_Day.new 2 10 52, Time_Of_Day.new 7 50 24, Time_Of_Day.new 5 46 13, Time_Of_Day.new 18 36 38, Time_Of_Day.new 15 34 42, Time_Of_Day.new 8 25 35]

        group_builder.specify "should be able to write dates In Excel 1904 format in legacy spreadsheet" <|
            xlsx_copy = enso_project.data / "transient" / "OlderDates1904Copy.xlsx"
            xlsx_copy.delete_if_exists . should_succeed
            (enso_project.data / "OlderDates1904.xlsx") . copy_to xlsx_copy

            numbers = [-100,-1,1,0,2,50,61,100]
            dates = numbers.map n-> (Date.new 1899 12 31).date_add n ..Day
            date_times = dates.map d-> d.to_date_time (Time_Of_Day.new 12 34 56)
            table = Table.new [["Num", numbers], ["Date", dates], ["DateTimes", date_times]]
            table.write xlsx_copy . should_succeed

            read_xlsx_copy = xlsx_copy.read
            read_xlsx_copy.sheet_names . should_equal ["Sheet1", "EnsoSheet"]

            read_table = read_xlsx_copy.read "EnsoSheet"
            read_table.should_equal table

            read_ref_table = read_xlsx_copy.read "Sheet1"
            ref_table = (enso_project.data / "OlderDates1904.xlsx") . read ..Sheet
            read_ref_table.should_equal ref_table

            xlsx_copy.delete_if_exists . should_succeed

        group_builder.specify "should be able to convert Excel dates from Integer to Date" <|
            numbers = [-100,-1,1,2,50,61,100]
            dates = [Date.new 1899 09 23, Date.new 1899 12 31, Date.new 1900 01 01, Date.new 1900 01 02, Date.new 1900 02 19, Date.new 1900 03 01, Date.new 1900 04 09]
            parsed = numbers.map n-> Date.from_excel n
            parsed . should_equal dates

            Date.from_excel 0 . should_fail_with Illegal_Argument
            Date.from_excel 60 . should_fail_with Illegal_Argument

        group_builder.specify "should be able to convert Excel dates from Integer to Date" <|
            numbers = [-100,-1,1,2,50,61,100]
            dates = [Date.new 1899 09 23, Date.new 1899 12 31, Date.new 1900 01 01, Date.new 1900 01 02, Date.new 1900 02 19, Date.new 1900 03 01, Date.new 1900 04 09]
            numbers_2 = numbers.map_with_index i->n-> n+(1+i*2)/24
            date_times = dates.map_with_index i->d-> (d.to_date_time (Time_Of_Day.new hour=1+i*2))
            parsed = numbers_2.map n-> Date_Time.from_excel n
            parsed . should_equal date_times

            Date_Time.from_excel 0.25 . should_fail_with Illegal_Argument
            Date_Time.from_excel 60.45 . should_fail_with Illegal_Argument

        ci_pending = if Environment.get "CI" != Nothing then "This test takes a lot of time so it is disabled on CI."
        group_builder.specify "should be able to write and read a big XLSX file (>110MB)" pending=ci_pending <|
            n = 10^6
            IO.println "Generating big XLSX file "+Time_Of_Day.now.to_text
            rng = RandomHelpers.new 123
            v = Vector.new n _->
                rng.makeRandomString 190
            table = Table.new [["X", v]]
            big_file = enso_project.data / "transient" / "big.xlsx"
            big_file.delete_if_exists

            table.write big_file on_existing_file=Existing_File_Behavior.Overwrite on_problems=..Report_Error . should_succeed
            IO.println "Done                     "+Time_Of_Day.now.to_text

            # Verify that the file is as big as we expected.
            size = big_file.size / (1024*1024)
            Test.with_clue "size="+size.to_text+"MB " <|
                (size > 110).should_be_true

            workbook = big_file.read
            sheets = workbook.sheet_names
            sheets.length . should_equal 1
            read_table = workbook.read (sheets.at 0)
            read_table.row_count . should_equal n+1
            read_table.column_names.length . should_equal 1
            read_table.at 0 . at 0 . should_equal "X"
            read_table.at 0 . at 1 . should_equal (v.at 0)

            workbook.close
            big_file.delete_if_exists . should_succeed

        group_builder.specify "should be able to write and read a big XLS file (>110MB)" pending=ci_pending <|
            IO.println "Generating big XLS file "+Time_Of_Day.now.to_text
            rng = RandomHelpers.new 123
            # Here we instead create a 2D table, because XLS has a limit of 65536 rows and 16k columns.
            rows = 65000
            cols = 20
            table = Table.new <| Vector.new cols i->
                v = Vector.new rows _-> rng.makeRandomString 100
                ["col" + i.to_text, v]
            big_file = enso_project.data / "transient" / "big.xls"
            big_file.delete_if_exists

            table.write big_file on_existing_file=Existing_File_Behavior.Overwrite on_problems=..Report_Error . should_succeed
            IO.println "Done                    "+Time_Of_Day.now.to_text

            # Verify that the file is as big as we expected.
            size = big_file.size / (1024*1024)
            Test.with_clue "size="+size.to_text+"MB " <|
                (size > 110).should_be_true

            workbook = big_file.read
            sheets = workbook.sheet_names
            sheets.length . should_equal 1
            read_table = workbook.read (sheets.at 0)
            read_table.row_count . should_equal rows+1
            read_table.column_names.length . should_equal cols

            workbook.close
            big_file.delete_if_exists . should_succeed

    spec_fmt suite_builder 'XLSX reading' Examples.xlsx .read

    spec_fmt suite_builder 'XLS reading' Examples.xls .read

    suite_builder.group "Reading single cells correctly" group_builder->
        file = enso_project.data / "RangeTests.xlsx"

        check_table table col_names data =
            table.column_count . should_equal col_names.length
            table.columns.map .name . should_equal col_names
            data.each_with_index idx->values->
                table.at (col_names.at idx) . to_vector . should_equal values

        group_builder.specify "Simple table" <|
            check_table (file.read (..Range "Sheet1!A1")) ["AA", "BB"] [[1,2,3,4,5,6], ["A","B","C","D","E","F"]]
            check_table (file.read (..Range "Sheet1!A2")) ["A", "B"] [[1,2,3,4,5,6], ["A","B","C","D","E","F"]]
            check_table (file.read (..Range "Sheet1!A1:A1")) ["A"] [["AA"]]
            check_table (file.read (..Range "Sheet1!B1")) ["B"] [["BB", "A","B","C","D","E","F"]]
            check_table (file.read (..Range "Sheet1!B1" headers=True)) ["BB"] [["A","B","C","D","E","F"]]
            check_table (file.read (..Range "Sheet1!B2")) ["B"] [["A","B","C","D","E","F"]]

        group_builder.specify "Patchy table" <|
            check_table (file.read (..Range "Sheet1!D1")) ["A", "B", "F"] [[1,2,4], [4,4,Nothing], [6,Nothing,6]]
            check_table (file.read (..Range "Sheet1!D2")) ["D", "E", "F"] [[1,2,4], [4,4,Nothing], [6,Nothing,6]]
            check_table (file.read (..Range "Sheet1!E")) ["B"] [[4,4,Nothing,Nothing,Nothing,Nothing]]
            check_table (file.read (..Range "Sheet1!E1")) ["B", "F"] [[4,4,Nothing], [6,Nothing,6]]
            check_table (file.read (..Range "Sheet1!E2")) ["E", "F"] [[4,4,Nothing], [6,Nothing,6]]

        group_builder.specify "Single cell" <|
            check_table (file.read (..Range "Sheet1!H1")) ["H"] [["Single Cell"]]
            check_table (file.read (..Range "Sheet1!H2")) ["H"] [[]]

        group_builder.specify "Single line" <|
            check_table (file.read (..Range "Sheet1!J1")) ["J", "K", "L"] [["Just"],["Some"],["Headers"]]

        group_builder.specify "Growing table" <|
            check_table (file.read (..Range "Sheet1!N1")) ["A", "Full", "Table", "Q"] [["Hello","World",Nothing,"Extend"],[1,Nothing,"Gap",3],[2,2,"Here",5],[Nothing,Nothing,"To","Hello"]]
            check_table (file.read (..Range "Sheet1!O1")) ["Full", "Table", "Q"] [[1,Nothing,"Gap",3],[2,2,"Here",5],[Nothing,Nothing,"To","Hello"]]
            check_table (file.read (..Range "Sheet1!O2")) ["O", "P", "Q"] [[1,Nothing,"Gap",3],[2,2,"Here",5],[Nothing,Nothing,"To","Hello"]]

        group_builder.specify "Should handle blank headers without warnings" <|
            check_table (file.read (..Range "Sheet1!D1")) ["A", "B", "F"] [[1,2,4], [4,4,Nothing], [6,Nothing,6]]

        group_builder.specify "Should handle duplicate headers with warnings" <|
            action = file.read (..Range "Sheet1!S1") on_problems=_
            tester = check_table _ ["DD", "DD 1"] [[1,3], [2,4]]
            problems = [Duplicate_Output_Column_Names.Error ["DD"]]
            Problems.test_problem_handling action problems tester

    spec_write suite_builder "xlsx" 'TestSheet.xlsx'
    spec_write suite_builder "xls" 'TestSheetOld.xls'

main filter=Nothing =
    suite = Test.build suite_builder->
        add_specs suite_builder
    suite.run_with_filter filter
